{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data, vertical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnfs.init(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "    def __init__(self, type: str) -> None:\n",
    "        self.type = type\n",
    "        \n",
    "\n",
    "\n",
    "class ReLu(ActivationFunction):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Relu\")\n",
    "        \n",
    "    def output(z: np.ndarray) -> np.ndarray:\n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    \n",
    "class Sigmoid(ActivationFunction):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Sigmoid\")\n",
    "        \n",
    "    def output(z: np.ndarray):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "class Softmax(ActivationFunction):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Sigmoid\")\n",
    "        \n",
    "    def output(z: np.ndarray):\n",
    "        exp_values = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_values / np.sum(exp_values, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, type: str, size: Tuple, activation: Type[ActivationFunction] | None) -> None:\n",
    "        self.type: str = type\n",
    "        self.size: Tuple = size\n",
    "        self.activation = activation\n",
    "        self.output = 0\n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return f\"Base Layer class\"\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "class Dense(Layer):\n",
    "     \n",
    "    def __init__(self, size: Tuple, activation: Type[ActivationFunction]) -> None:\n",
    "        super().__init__(\"Dense\", size, activation)\n",
    "        self.weights = np.random.rand(*size) * 0.01\n",
    "        self.biases = np.zeros((1, size[1]))\n",
    "        \n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return f\"- {self.type} -\\nWeights:\\n{self.weights}\\n{'-'*15}\\nBias: {self.biases}\"\n",
    "\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> None:\n",
    "        self.output = self.activation.output(np.dot(x, self.weights) + self.biases)\n",
    "\n",
    "    \n",
    "\n",
    "class Input(Layer):\n",
    "    def __init__(self, inputs: np.ndarray) -> None:\n",
    "        super().__init__(\"Input\", inputs.size, None)\n",
    "        self.output = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self, type: str) -> None:\n",
    "        self.type= type\n",
    "        self.output = 0\n",
    "        \n",
    "    def calculate(self, output: np.ndarray, y_true: np.ndarray) -> float:\n",
    "        \n",
    "        self.forward(output, y_true)\n",
    "        \n",
    "        return np.mean(self.output)\n",
    "\n",
    "\n",
    "class CategoricalCrossEntropy(Loss):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Categorical\")\n",
    "        \n",
    "    def forward(self, y_pred: np.ndarray, y_true: np.ndarray) -> np.ndarray:\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        \n",
    "        correct_confidences = y_pred_clipped[range(len(y_pred)), y_true]\n",
    "        self.output = -np.log(correct_confidences)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy:\n",
    "    def calculate(self, y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
    "        \n",
    "        return np.mean(np.argmax(y_pred, axis=1) == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self) -> None:\n",
    "        self.layers: np.ndarray[Type[Layer]] = np.array([])\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return \",\\n\".join([f\"Layer {layer.type} (size={layer.size})\" for layer in self.layers])\n",
    "    \n",
    "    def add(self, layer: Type[Layer]) -> None:\n",
    "        self.layers = np.append(self.layers, layer)\n",
    "        \n",
    "    def propagate_forward(self) -> np.ndarray:\n",
    "        z = self.layers[0].forward()\n",
    "        for layer in self.layers[1:]:\n",
    "            z = layer.activation.output(layer.forward(z))\n",
    "            \n",
    "        print(z)  \n",
    "        return CategoricalCrossEntropy().output(z, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = vertical_data(samples=100, classes=3)\n",
    "\n",
    "dense1 = Dense(size=(2, 64), activation=ReLu)\n",
    "dense2 = Dense(size=(64, 64), activation=ReLu)\n",
    "dense3 = Dense(size=(64, 3), activation=Softmax)\n",
    "\n",
    "loss_function = CategoricalCrossEntropy()\n",
    "\n",
    "accuracy_function = Accuracy()\n",
    "min_loss = 99999\n",
    "max_acc = 0\n",
    "best_dense1_weights = dense1.weights.copy()\n",
    "best_dense1_biases = dense1.biases.copy()\n",
    "best_dense2_weights = dense2.weights.copy()\n",
    "best_dense2_biases = dense2.biases.copy()\n",
    "best_dense3_weights = dense3.weights.copy()\n",
    "best_dense3_biases = dense3.biases.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = vertical_data(samples=100, classes=3)\n",
    "\n",
    "dense1 = Dense(size=(2, 16), activation=ReLu)\n",
    "dense2 = Dense(size=(16, 16), activation=Softmax)\n",
    "dense3 = Dense(size=(16, 3), activation=Softmax)\n",
    "\n",
    "loss_function = CategoricalCrossEntropy()\n",
    "\n",
    "accuracy_function = Accuracy()\n",
    "\n",
    "min_loss = 99999\n",
    "max_acc = 0\n",
    "best_dense1_weights = dense1.weights.copy()\n",
    "best_dense1_biases = dense1.biases.copy()\n",
    "best_dense2_weights = dense2.weights.copy()\n",
    "best_dense2_biases = dense2.biases.copy()\n",
    "best_dense3_weights = dense3.weights.copy()\n",
    "best_dense3_biases = dense3.biases.copy()\n",
    "\n",
    "for epoch in range(100000):\n",
    "    \n",
    "    dense1.weights += 0.05 * np.random.rand(*dense1.size)\n",
    "    dense1.biases += 0.05 * np.random.rand(1, dense1.size[1])\n",
    "    dense2.weights += 0.05 * np.random.rand(*dense2.size)\n",
    "    dense2.biases += 0.05 * np.random.rand(1, dense2.size[1])\n",
    "    dense3.weights += 0.05 * np.random.rand(*dense3.size)\n",
    "    dense3.biases += 0.05 * np.random.rand(1, dense3.size[1])\n",
    "    \n",
    "    dense1.forward(X)\n",
    "    dense2.forward(dense1.output)\n",
    "    dense3.forward(dense2.output)\n",
    "    loss = loss_function.calculate(dense2.output, y)\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_function.calculate(dense2.output, y)\n",
    "    \n",
    "    if loss < min_loss:\n",
    "        best_dense1_weights = dense1.weights.copy()\n",
    "        best_dense1_biases = dense1.biases.copy()\n",
    "        best_dense2_weights = dense2.weights.copy()\n",
    "        best_dense2_biases = dense2.biases.copy()\n",
    "        best_dense3_weights = dense3.weights.copy()\n",
    "        best_dense3_biases = dense3.biases.copy()\n",
    "        \n",
    "        print(f\"{epoch}. New values found. Loss: {loss}. Acc: {accuracy}\")\n",
    "        \n",
    "        max_acc = accuracy\n",
    "        min_loss = loss\n",
    "    \n",
    "    else:\n",
    "        dense1.weights = best_dense1_weights.copy()\n",
    "        dense1.biases = best_dense1_biases.copy()\n",
    "        dense2.weights = best_dense2_weights.copy()\n",
    "        dense2.biases = best_dense2_biases.copy()\n",
    "        dense3.weights = best_dense3_weights.copy()\n",
    "        dense3.biases = best_dense3_biases.copy()\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
